<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />



<title>Extrinsic variable selection</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>



<style type="text/css">
code {
white-space: pre;
}
.sourceCode {
overflow: visible;
}
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
{ counter-reset: source-line 0; }
pre.numberSource code > span
{ position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
{ content: counter(source-line);
position: relative; left: -1em; text-align: right; vertical-align: baseline;
border: none; display: inline-block;
-webkit-touch-callout: none; -webkit-user-select: none;
-khtml-user-select: none; -moz-user-select: none;
-ms-user-select: none; user-select: none;
padding: 0 4px; width: 4em;
color: #aaaaaa;
}
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }
div.sourceCode
{ }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } 
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.at { color: #7d9029; } 
code span.bn { color: #40a070; } 
code span.bu { color: #008000; } 
code span.cf { color: #007020; font-weight: bold; } 
code span.ch { color: #4070a0; } 
code span.cn { color: #880000; } 
code span.co { color: #60a0b0; font-style: italic; } 
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.do { color: #ba2121; font-style: italic; } 
code span.dt { color: #902000; } 
code span.dv { color: #40a070; } 
code span.er { color: #ff0000; font-weight: bold; } 
code span.ex { } 
code span.fl { color: #40a070; } 
code span.fu { color: #06287e; } 
code span.im { color: #008000; font-weight: bold; } 
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.kw { color: #007020; font-weight: bold; } 
code span.op { color: #666666; } 
code span.ot { color: #007020; } 
code span.pp { color: #bc7a00; } 
code span.sc { color: #4070a0; } 
code span.ss { color: #bb6688; } 
code span.st { color: #4070a0; } 
code span.va { color: #19177c; } 
code span.vs { color: #4070a0; } 
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } 
</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>




<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Extrinsic variable selection</h1>



<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;flevr&quot;</span>)</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="co">#&gt; flevr version 0.0.4: Flexible, Ensemble-Based Variable Selection with Potentially Missing Data</span></span></code></pre></div>
<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>In the <a href="introduction_to_flevr.html">main vignette</a>, I
discussed how to perform flexible variable selection in a simple,
simulated example. In this document, I will discuss <em>extrinsic
selection</em> in more detail.</p>
<p>Extrinsic variable selection is variable selection performed using
extrinsic variable importance <span class="citation">[@williamson2021]</span>. Extrinsic variable importance
is a summary of how a particular fitted algorithm makes use of the input
features. For example, extrinsic importance for a penalized regression
model could be the estimated regression coefficient, while for random
forests, it could be the random forest variable importance measure.</p>
<p>In <code>flevr</code>, we use the following definitions of variable
importance</p>
<table>
<colgroup>
<col width="53%" />
<col width="46%" />
</colgroup>
<thead>
<tr class="header">
<th>Algorithm</th>
<th><code>R</code> package implementation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Generalized linear models</td>
<td><code>stats::glm</code></td>
</tr>
<tr class="even">
<td>Penalized linear models</td>
<td><code>glmnet::glmnet</code> <span class="citation">[@friedman2010;@tay2023;@glmnet]</span></td>
</tr>
<tr class="odd">
<td>Mean</td>
<td><code>stats::mean</code></td>
</tr>
<tr class="even">
<td>Multivariate adaptive regression splines</td>
<td><code>polspline::polymars</code> <span class="citation">[@polspline]</span></td>
</tr>
<tr class="odd">
<td>Random forests</td>
<td>`<code>ranger::ranger</code> <span class="citation">[@ranger;@wright2017]</span></td>
</tr>
<tr class="even">
<td>Support vector machines</td>
<td><code>kernlab::ksvm</code> <span class="citation">[@karatzoglou2004;@kernlab]</span></td>
</tr>
<tr class="odd">
<td>Gradient boosted trees</td>
<td><code>xgboost::xgboost</code> <span class="citation">[@xgboost]</span></td>
</tr>
</tbody>
</table>
<p>Further, we define the extrinsic importance of the Super Learner
<span class="citation">[@vanderlaan2007]</span>. The first choice is to
use the weighted average of the variable importance ranks of the
individual learners. The weights are determined by the Super Learner
itself, since the algorithm determines a weighted combination of the
individual-learner predictions. The second choice is to use the variable
importance from the best-performing individual learner.</p>
<p>Throughout this vignette, I will use a dataset inspired by data
collected by the Early Detection Research Network (EDRN). Biomarkers
developed at six “labs” are validated at at least one of four
“validation sites” on 306 cysts. The data also include two binary
outcome variables: whether or not the cyst was classified as mucinous,
and whether or not the cyst was determined to have high malignant
potential. The data contain some missing information, which complicates
variable selection; only 212 cysts have complete information. In the
first section, we will drop the missing data; in the second section, we
will appropriately handle the missing data by using multiple
imputation.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="co"># load the dataset</span></span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;biomarkers&quot;</span>)</span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;dplyr&quot;</span>)</span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a><span class="co">#&gt; Attaching package: &#39;dplyr&#39;</span></span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a><span class="co">#&gt; The following objects are masked from &#39;package:stats&#39;:</span></span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a><span class="co">#&gt;     filter, lag</span></span>
<span id="cb2-9"><a href="#cb2-9" tabindex="-1"></a><span class="co">#&gt; The following objects are masked from &#39;package:base&#39;:</span></span>
<span id="cb2-10"><a href="#cb2-10" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb2-11"><a href="#cb2-11" tabindex="-1"></a><span class="co">#&gt;     intersect, setdiff, setequal, union</span></span>
<span id="cb2-12"><a href="#cb2-12" tabindex="-1"></a><span class="co"># set up vector &quot;y&quot; of outcomes and matrix &quot;x&quot; of features</span></span>
<span id="cb2-13"><a href="#cb2-13" tabindex="-1"></a>cc <span class="ot">&lt;-</span> <span class="fu">complete.cases</span>(biomarkers)</span>
<span id="cb2-14"><a href="#cb2-14" tabindex="-1"></a>y_cc <span class="ot">&lt;-</span> biomarkers<span class="sc">$</span>mucinous[cc]</span>
<span id="cb2-15"><a href="#cb2-15" tabindex="-1"></a>x_cc <span class="ot">&lt;-</span> biomarkers <span class="sc">%&gt;%</span></span>
<span id="cb2-16"><a href="#cb2-16" tabindex="-1"></a>  <span class="fu">na.omit</span>() <span class="sc">%&gt;%</span></span>
<span id="cb2-17"><a href="#cb2-17" tabindex="-1"></a>  <span class="fu">select</span>(<span class="fu">starts_with</span>(<span class="st">&quot;lab&quot;</span>), <span class="fu">starts_with</span>(<span class="st">&quot;cea&quot;</span>))</span>
<span id="cb2-18"><a href="#cb2-18" tabindex="-1"></a>x_df <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(x_cc)</span>
<span id="cb2-19"><a href="#cb2-19" tabindex="-1"></a>x_names <span class="ot">&lt;-</span> <span class="fu">names</span>(x_df)</span></code></pre></div>
</div>
<div id="extrinsic-variable-selection" class="section level2">
<h2>Extrinsic variable selection</h2>
<p>The first step in performing extrinsic variable selection is to fit a
Super Learner. This requires specifying a <em>library of candidate
learners</em> for the Super Learner <span class="citation">[@vanderlaan2007;@superlearner]</span>; throughout, I
use a very simple library of learners for the Super Learner (this is for
illustration only; in practice, I suggest using a large library of
learners).</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a><span class="co"># fit a Super Learner ensemble; note its simplicity, for speed</span></span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;SuperLearner&quot;</span>)</span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a><span class="co">#&gt; Loading required package: nnls</span></span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a><span class="co">#&gt; Loading required package: gam</span></span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a><span class="co">#&gt; Loading required package: splines</span></span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a><span class="co">#&gt; Loading required package: foreach</span></span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a><span class="co">#&gt; Loaded gam 1.22-2</span></span>
<span id="cb3-9"><a href="#cb3-9" tabindex="-1"></a><span class="co">#&gt; Super Learner</span></span>
<span id="cb3-10"><a href="#cb3-10" tabindex="-1"></a><span class="co">#&gt; Version: 2.0-28.1</span></span>
<span id="cb3-11"><a href="#cb3-11" tabindex="-1"></a><span class="co">#&gt; Package created on 2021-05-04</span></span>
<span id="cb3-12"><a href="#cb3-12" tabindex="-1"></a>learners <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;SL.glm&quot;</span>, <span class="st">&quot;SL.ranger.imp&quot;</span>, <span class="st">&quot;SL.glmnet&quot;</span>)</span>
<span id="cb3-13"><a href="#cb3-13" tabindex="-1"></a>V <span class="ot">&lt;-</span> <span class="dv">2</span></span>
<span id="cb3-14"><a href="#cb3-14" tabindex="-1"></a>fit <span class="ot">&lt;-</span> SuperLearner<span class="sc">::</span><span class="fu">SuperLearner</span>(<span class="at">Y =</span> y_cc, <span class="at">X =</span> x_df,</span>
<span id="cb3-15"><a href="#cb3-15" tabindex="-1"></a>                                  <span class="at">SL.library =</span> learners,</span>
<span id="cb3-16"><a href="#cb3-16" tabindex="-1"></a>                                  <span class="at">cvControl =</span> <span class="fu">list</span>(<span class="at">V =</span> V),</span>
<span id="cb3-17"><a href="#cb3-17" tabindex="-1"></a>                                  <span class="at">family =</span> <span class="st">&quot;binomial&quot;</span>)</span>
<span id="cb3-18"><a href="#cb3-18" tabindex="-1"></a><span class="co">#&gt; Loading required namespace: glmnet</span></span>
<span id="cb3-19"><a href="#cb3-19" tabindex="-1"></a><span class="co">#&gt; Loading required namespace: ranger</span></span>
<span id="cb3-20"><a href="#cb3-20" tabindex="-1"></a><span class="co">#&gt; Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :</span></span>
<span id="cb3-21"><a href="#cb3-21" tabindex="-1"></a><span class="co">#&gt; prediction from rank-deficient fit; attr(*, &quot;non-estim&quot;) has doubtful cases</span></span>
<span id="cb3-22"><a href="#cb3-22" tabindex="-1"></a><span class="co"># check the SL weights</span></span>
<span id="cb3-23"><a href="#cb3-23" tabindex="-1"></a>fit<span class="sc">$</span>coef</span>
<span id="cb3-24"><a href="#cb3-24" tabindex="-1"></a><span class="co">#&gt;        SL.glm_All SL.ranger.imp_All     SL.glmnet_All </span></span>
<span id="cb3-25"><a href="#cb3-25" tabindex="-1"></a><span class="co">#&gt;         0.0000000         0.7667208         0.2332792</span></span>
<span id="cb3-26"><a href="#cb3-26" tabindex="-1"></a><span class="co"># extract importance based on the whole Super Learner</span></span>
<span id="cb3-27"><a href="#cb3-27" tabindex="-1"></a>sl_importance_all <span class="ot">&lt;-</span> <span class="fu">extract_importance_SL</span>(</span>
<span id="cb3-28"><a href="#cb3-28" tabindex="-1"></a>  <span class="at">fit =</span> fit, <span class="at">feature_names =</span> x_names, <span class="at">import_type =</span> <span class="st">&quot;all&quot;</span></span>
<span id="cb3-29"><a href="#cb3-29" tabindex="-1"></a>)</span>
<span id="cb3-30"><a href="#cb3-30" tabindex="-1"></a>sl_importance_all</span>
<span id="cb3-31"><a href="#cb3-31" tabindex="-1"></a><span class="co">#&gt; # A tibble: 21 × 2</span></span>
<span id="cb3-32"><a href="#cb3-32" tabindex="-1"></a><span class="co">#&gt;    feature                  rank</span></span>
<span id="cb3-33"><a href="#cb3-33" tabindex="-1"></a><span class="co">#&gt;    &lt;chr&gt;                   &lt;dbl&gt;</span></span>
<span id="cb3-34"><a href="#cb3-34" tabindex="-1"></a><span class="co">#&gt;  1 lab3_muc3ac_score        3.33</span></span>
<span id="cb3-35"><a href="#cb3-35" tabindex="-1"></a><span class="co">#&gt;  2 lab6_ab_score            4.10</span></span>
<span id="cb3-36"><a href="#cb3-36" tabindex="-1"></a><span class="co">#&gt;  3 lab1_actb                4.87</span></span>
<span id="cb3-37"><a href="#cb3-37" tabindex="-1"></a><span class="co">#&gt;  4 lab1_telomerase_score    5.63</span></span>
<span id="cb3-38"><a href="#cb3-38" tabindex="-1"></a><span class="co">#&gt;  5 cea                      6.40</span></span>
<span id="cb3-39"><a href="#cb3-39" tabindex="-1"></a><span class="co">#&gt;  6 lab4_glucose_score       7.17</span></span>
<span id="cb3-40"><a href="#cb3-40" tabindex="-1"></a><span class="co">#&gt;  7 lab4_areg_score          7.93</span></span>
<span id="cb3-41"><a href="#cb3-41" tabindex="-1"></a><span class="co">#&gt;  8 lab2_fluorescence_score  8.70</span></span>
<span id="cb3-42"><a href="#cb3-42" tabindex="-1"></a><span class="co">#&gt;  9 lab3_muc5ac_score        9.47</span></span>
<span id="cb3-43"><a href="#cb3-43" tabindex="-1"></a><span class="co">#&gt; 10 lab1_molecules_score    10.2 </span></span>
<span id="cb3-44"><a href="#cb3-44" tabindex="-1"></a><span class="co">#&gt; # ℹ 11 more rows</span></span></code></pre></div>
<p>Using the ensemble weights here means that weight approximately 0.53
is given to the boosted trees, weight approximately 0.47 is given to the
random forest, while weight 0 is given to the logistic regression
model.</p>
<p>To instead look at the importance of the best individual learner, use
the following code:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a>sl_importance_best <span class="ot">&lt;-</span> <span class="fu">extract_importance_SL</span>(</span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a>  <span class="at">fit =</span> fit, <span class="at">feature_names =</span> x_names, <span class="at">import_type =</span> <span class="st">&quot;best&quot;</span></span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a>)</span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a>sl_importance_best</span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a><span class="co">#&gt; # A tibble: 21 × 2</span></span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a><span class="co">#&gt;    feature                  rank</span></span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a><span class="co">#&gt;    &lt;chr&gt;                   &lt;dbl&gt;</span></span>
<span id="cb4-8"><a href="#cb4-8" tabindex="-1"></a><span class="co">#&gt;  1 lab3_muc3ac_score           1</span></span>
<span id="cb4-9"><a href="#cb4-9" tabindex="-1"></a><span class="co">#&gt;  2 lab6_ab_score               2</span></span>
<span id="cb4-10"><a href="#cb4-10" tabindex="-1"></a><span class="co">#&gt;  3 lab1_actb                   3</span></span>
<span id="cb4-11"><a href="#cb4-11" tabindex="-1"></a><span class="co">#&gt;  4 lab1_telomerase_score       4</span></span>
<span id="cb4-12"><a href="#cb4-12" tabindex="-1"></a><span class="co">#&gt;  5 cea                         5</span></span>
<span id="cb4-13"><a href="#cb4-13" tabindex="-1"></a><span class="co">#&gt;  6 lab4_glucose_score          6</span></span>
<span id="cb4-14"><a href="#cb4-14" tabindex="-1"></a><span class="co">#&gt;  7 lab4_areg_score             7</span></span>
<span id="cb4-15"><a href="#cb4-15" tabindex="-1"></a><span class="co">#&gt;  8 lab2_fluorescence_score     8</span></span>
<span id="cb4-16"><a href="#cb4-16" tabindex="-1"></a><span class="co">#&gt;  9 lab3_muc5ac_score           9</span></span>
<span id="cb4-17"><a href="#cb4-17" tabindex="-1"></a><span class="co">#&gt; 10 lab1_molecules_score       10</span></span>
<span id="cb4-18"><a href="#cb4-18" tabindex="-1"></a><span class="co">#&gt; # ℹ 11 more rows</span></span></code></pre></div>
<p>In this case, this shows the importance in the boosted trees.</p>
<p>Finally, to do variable selection, we need to select a threshold
(ideally before looking at the data). In this case, since there are only
24 variables, we choose a threshold of 5.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a>extrinsic_selected <span class="ot">&lt;-</span> <span class="fu">extrinsic_selection</span>(</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a>  <span class="at">fit =</span> fit, <span class="at">feature_names =</span> x_names, <span class="at">threshold =</span> <span class="dv">5</span>, <span class="at">import_type =</span> <span class="st">&quot;all&quot;</span></span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a>)</span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a>extrinsic_selected</span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a><span class="co">#&gt; # A tibble: 21 × 3</span></span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a><span class="co">#&gt;    feature                  rank selected</span></span>
<span id="cb5-7"><a href="#cb5-7" tabindex="-1"></a><span class="co">#&gt;    &lt;chr&gt;                   &lt;dbl&gt; &lt;lgl&gt;   </span></span>
<span id="cb5-8"><a href="#cb5-8" tabindex="-1"></a><span class="co">#&gt;  1 lab3_muc3ac_score        3.33 TRUE    </span></span>
<span id="cb5-9"><a href="#cb5-9" tabindex="-1"></a><span class="co">#&gt;  2 lab6_ab_score            4.10 TRUE    </span></span>
<span id="cb5-10"><a href="#cb5-10" tabindex="-1"></a><span class="co">#&gt;  3 lab1_actb                4.87 TRUE    </span></span>
<span id="cb5-11"><a href="#cb5-11" tabindex="-1"></a><span class="co">#&gt;  4 lab1_telomerase_score    5.63 FALSE   </span></span>
<span id="cb5-12"><a href="#cb5-12" tabindex="-1"></a><span class="co">#&gt;  5 cea                      6.40 FALSE   </span></span>
<span id="cb5-13"><a href="#cb5-13" tabindex="-1"></a><span class="co">#&gt;  6 lab4_glucose_score       7.17 FALSE   </span></span>
<span id="cb5-14"><a href="#cb5-14" tabindex="-1"></a><span class="co">#&gt;  7 lab4_areg_score          7.93 FALSE   </span></span>
<span id="cb5-15"><a href="#cb5-15" tabindex="-1"></a><span class="co">#&gt;  8 lab2_fluorescence_score  8.70 FALSE   </span></span>
<span id="cb5-16"><a href="#cb5-16" tabindex="-1"></a><span class="co">#&gt;  9 lab3_muc5ac_score        9.47 FALSE   </span></span>
<span id="cb5-17"><a href="#cb5-17" tabindex="-1"></a><span class="co">#&gt; 10 lab1_molecules_score    10.2  FALSE   </span></span>
<span id="cb5-18"><a href="#cb5-18" tabindex="-1"></a><span class="co">#&gt; # ℹ 11 more rows</span></span></code></pre></div>
<p>Here, we select five variables, since these had weighted rank less
than 5.</p>
</div>
<div id="extrinsic-selection-with-missing-data" class="section level2">
<h2>Extrinsic selection with missing data</h2>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a>n_imp <span class="ot">&lt;-</span> <span class="dv">2</span></span></code></pre></div>
<p>To properly handle the missing data, we first perform multiple
imputation. We use the <code>R</code> package <code>mice</code>, here
with only 2 imputations (in practice, more imputations may be
better).</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;mice&quot;</span>)</span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">20231121</span>)</span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a>mi_biomarkers <span class="ot">&lt;-</span> mice<span class="sc">::</span><span class="fu">mice</span>(<span class="at">data =</span> biomarkers, <span class="at">m =</span> n_imp, <span class="at">printFlag =</span> <span class="cn">FALSE</span>)</span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a>imputed_biomarkers <span class="ot">&lt;-</span> mice<span class="sc">::</span><span class="fu">complete</span>(mi_biomarkers, <span class="at">action =</span> <span class="st">&quot;long&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a>  <span class="fu">rename</span>(<span class="at">imp =</span> .imp, <span class="at">id =</span> .id)</span></code></pre></div>
<p>We can perform extrinsic variable selection using the imputed data.
First, we fit a Super Learner and perform extrinsic variable selection
for each imputed dataset. Then, we select a final set of variables based
on those that are selected in a pre-specified number of imputed datasets
(e.g., 3 of 5) <span class="citation">[@heymans2007]</span>. Again, we
use a rank of 5 for each imputed dataset to select variables.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">20231121</span>)</span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a><span class="co"># set up a list to collect selected sets</span></span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a>all_selected_vars <span class="ot">&lt;-</span> <span class="fu">vector</span>(<span class="st">&quot;list&quot;</span>, <span class="at">length =</span> <span class="dv">5</span>)</span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a><span class="co"># for each imputed dataset, do extrinsic selection</span></span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n_imp) {</span>
<span id="cb8-6"><a href="#cb8-6" tabindex="-1"></a>  <span class="co"># fit a Super Learner</span></span>
<span id="cb8-7"><a href="#cb8-7" tabindex="-1"></a>  these_data <span class="ot">&lt;-</span> imputed_biomarkers <span class="sc">%&gt;%</span></span>
<span id="cb8-8"><a href="#cb8-8" tabindex="-1"></a>    <span class="fu">filter</span>(imp <span class="sc">==</span> i)</span>
<span id="cb8-9"><a href="#cb8-9" tabindex="-1"></a>  this_y <span class="ot">&lt;-</span> these_data<span class="sc">$</span>mucinous</span>
<span id="cb8-10"><a href="#cb8-10" tabindex="-1"></a>  this_x <span class="ot">&lt;-</span> these_data <span class="sc">%&gt;%</span></span>
<span id="cb8-11"><a href="#cb8-11" tabindex="-1"></a>    <span class="fu">select</span>(<span class="fu">starts_with</span>(<span class="st">&quot;lab&quot;</span>), <span class="fu">starts_with</span>(<span class="st">&quot;cea&quot;</span>))</span>
<span id="cb8-12"><a href="#cb8-12" tabindex="-1"></a>  this_x_df <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(this_x)</span>
<span id="cb8-13"><a href="#cb8-13" tabindex="-1"></a>  fit <span class="ot">&lt;-</span> SuperLearner<span class="sc">::</span><span class="fu">SuperLearner</span>(<span class="at">Y =</span> this_y, <span class="at">X =</span> this_x_df,</span>
<span id="cb8-14"><a href="#cb8-14" tabindex="-1"></a>                                  <span class="at">SL.library =</span> learners,</span>
<span id="cb8-15"><a href="#cb8-15" tabindex="-1"></a>                                  <span class="at">cvControl =</span> <span class="fu">list</span>(<span class="at">V =</span> V),</span>
<span id="cb8-16"><a href="#cb8-16" tabindex="-1"></a>                                  <span class="at">family =</span> <span class="st">&quot;binomial&quot;</span>)</span>
<span id="cb8-17"><a href="#cb8-17" tabindex="-1"></a>  <span class="co"># do extrinsic selection</span></span>
<span id="cb8-18"><a href="#cb8-18" tabindex="-1"></a>  all_selected_vars[[i]] <span class="ot">&lt;-</span> <span class="fu">extrinsic_selection</span>(</span>
<span id="cb8-19"><a href="#cb8-19" tabindex="-1"></a>    <span class="at">fit =</span> fit, <span class="at">feature_names =</span> x_names, <span class="at">threshold =</span> <span class="dv">5</span>, <span class="at">import_type =</span> <span class="st">&quot;all&quot;</span></span>
<span id="cb8-20"><a href="#cb8-20" tabindex="-1"></a>  )<span class="sc">$</span>selected</span>
<span id="cb8-21"><a href="#cb8-21" tabindex="-1"></a>}</span>
<span id="cb8-22"><a href="#cb8-22" tabindex="-1"></a><span class="co"># perform extrinsic variable selection</span></span>
<span id="cb8-23"><a href="#cb8-23" tabindex="-1"></a>selected_vars <span class="ot">&lt;-</span> <span class="fu">pool_selected_sets</span>(<span class="at">sets =</span> all_selected_vars, <span class="at">threshold =</span> <span class="dv">1</span> <span class="sc">/</span> n_imp)</span>
<span id="cb8-24"><a href="#cb8-24" tabindex="-1"></a>x_names[selected_vars]</span></code></pre></div>
<p>In this case, there is only one variable in common between the
multiply-imputed approach and the approach dropping missing data. This
serves to highlight that it is important in missing-data contexts to
handle the missing data appropriately.</p>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
